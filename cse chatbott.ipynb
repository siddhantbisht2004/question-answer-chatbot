{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJdq6pHBKSsA1ks5/eDaW6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install PyPDF2 python-docx sentence-transformers scikit-learn flask flask-cors"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"av91HZnB8YEG","executionInfo":{"status":"ok","timestamp":1737112003157,"user_tz":-330,"elapsed":3213,"user":{"displayName":"SIDDHANT BISHT","userId":"12873535686418561845"}},"outputId":"8dcbf385-8f84-41d8-8360-9bc6b46e867d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n","Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n","Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n","Collecting flask-cors\n","  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n","Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.0)\n","Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.47.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu121)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.27.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n","Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n","Installing collected packages: flask-cors\n","Successfully installed flask-cors-5.0.0\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","import os\n","\n","# Create upload directory\n","upload_directory = \"./uploaded_files\"\n","os.makedirs(upload_directory, exist_ok=True)\n","\n","# Upload files\n","uploaded = files.upload()\n","\n","# Save uploaded files\n","for filename in uploaded.keys():\n","    file_path = os.path.join(upload_directory, filename)\n","    with open(file_path, 'wb') as f:\n","        f.write(uploaded[filename])\n","    print(f\"Uploaded file: {filename}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"E4PgUTHs8bej","executionInfo":{"status":"ok","timestamp":1737112037358,"user_tz":-330,"elapsed":11697,"user":{"displayName":"SIDDHANT BISHT","userId":"12873535686418561845"}},"outputId":"1059735c-d781-42b5-ba4b-2d8e788b2989"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-97c5586c-e2fa-4263-be76-c8b01fb74b98\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-97c5586c-e2fa-4263-be76-c8b01fb74b98\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving CSE DEPARTMENT INFO.txt to CSE DEPARTMENT INFO.txt\n","Uploaded file: CSE DEPARTMENT INFO.txt\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","from typing import List, Dict\n","import PyPDF2\n","import docx\n","import logging\n","import traceback\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import time\n","\n","# Set up logging\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","class DocumentProcessor:\n","    \"\"\"Handles document loading and text extraction from various file formats.\"\"\"\n","\n","    @staticmethod\n","    def read_text_file(file_path: str) -> str:\n","        \"\"\"Read content from text files.\"\"\"\n","        try:\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                return file.read()\n","        except UnicodeDecodeError:\n","            # Try with a different encoding if utf-8 fails\n","            with open(file_path, 'r', encoding='latin-1') as file:\n","                return file.read()\n","\n","    @staticmethod\n","    def read_pdf_file(file_path: str) -> str:\n","        \"\"\"Read content from PDF files.\"\"\"\n","        text = \"\"\n","        try:\n","            with open(file_path, 'rb') as file:\n","                pdf_reader = PyPDF2.PdfReader(file)\n","                for page in pdf_reader.pages:\n","                    text += page.extract_text() + \"\\n\"\n","            return text\n","        except Exception as e:\n","            logger.error(f\"Error reading PDF {file_path}: {str(e)}\")\n","            return \"\"\n","\n","    @staticmethod\n","    def read_word_file(file_path: str) -> str:\n","        \"\"\"Read content from Word documents.\"\"\"\n","        try:\n","            doc = docx.Document(file_path)\n","            return \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n","        except Exception as e:\n","            logger.error(f\"Error reading Word document {file_path}: {str(e)}\")\n","            return \"\"\n","\n","    @staticmethod\n","    def process_directory(directory_path: str) -> List[Dict]:\n","        \"\"\"Process all supported documents in a directory.\"\"\"\n","        processed_docs = []\n","        supported_extensions = {'.txt', '.pdf', '.docx'}\n","\n","        try:\n","            for root, _, files in os.walk(directory_path):\n","                for file in files:\n","                    file_path = os.path.join(root, file)\n","                    extension = os.path.splitext(file)[1].lower()\n","\n","                    if extension not in supported_extensions:\n","                        continue\n","\n","                    try:\n","                        print(f\"Processing file: {file_path}\")\n","                        if extension == '.txt':\n","                            content = DocumentProcessor.read_text_file(file_path)\n","                        elif extension == '.pdf':\n","                            content = DocumentProcessor.read_pdf_file(file_path)\n","                        elif extension == '.docx':\n","                            content = DocumentProcessor.read_word_file(file_path)\n","                        else:\n","                            continue\n","\n","                        if not content.strip():\n","                            print(f\"Warning: No content extracted from {file_path}\")\n","                            continue\n","\n","                        chunks = DocumentProcessor.chunk_text(content)\n","                        print(f\"Created {len(chunks)} chunks from {file_path}\")\n","\n","                        for chunk in chunks:\n","                            processed_docs.append({\n","                                \"content\": chunk,\n","                                \"metadata\": {\n","                                    \"source\": file_path,\n","                                    \"type\": extension[1:],\n","                                    \"chunk_size\": len(chunk)\n","                                }\n","                            })\n","\n","                    except Exception as e:\n","                        logger.error(f\"Error processing {file_path}: {str(e)}\")\n","                        print(traceback.format_exc())\n","\n","            return processed_docs\n","\n","        except Exception as e:\n","            logger.error(f\"Error walking directory {directory_path}: {str(e)}\")\n","            print(traceback.format_exc())\n","            return []\n","\n","    @staticmethod\n","    def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 100) -> List[str]:\n","        \"\"\"Split text into overlapping chunks.\"\"\"\n","        chunks = []\n","        start = 0\n","        text_length = len(text)\n","\n","        while start < text_length:\n","            end = start + chunk_size\n","\n","            if end < text_length:\n","                # Find the last space before chunk_size\n","                while end > start and text[end] != ' ':\n","                    end -= 1\n","\n","            chunk = text[start:end].strip()\n","            if chunk:  # Only add non-empty chunks\n","                chunks.append(chunk)\n","\n","            start = end - overlap\n","\n","        return chunks\n","\n","class CSEChatbot:\n","    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n","        \"\"\"Initialize the chatbot with necessary components.\"\"\"\n","        try:\n","            print(\"Initializing SentenceTransformer...\")\n","            self.encoder = SentenceTransformer(model_name)\n","            self.documents = []\n","            self.embeddings = None\n","            print(\"Initialization successful\")\n","        except Exception as e:\n","            print(f\"Error initializing chatbot: {str(e)}\")\n","            print(traceback.format_exc())\n","            raise\n","\n","    def load_documents(self, directory_path: str):\n","        \"\"\"Load and process documents from the specified directory.\"\"\"\n","        try:\n","            logger.info(f\"Processing documents from {directory_path}\")\n","            print(f\"Processing documents from {directory_path}\")\n","\n","            # Process documents\n","            docs = DocumentProcessor.process_directory(directory_path)\n","            self.documents = docs\n","\n","            print(f\"Number of documents processed: {len(self.documents)}\")\n","            if len(self.documents) > 0:\n","                print(f\"Sample document content: {self.documents[0]['content'][:200]}...\")\n","\n","            if not self.documents:\n","                print(\"Warning: No documents were processed.\")\n","                return\n","\n","            # Generate embeddings\n","            print(\"Generating embeddings...\")\n","            texts = [doc[\"content\"] for doc in self.documents]\n","            self.embeddings = self.encoder.encode(texts, show_progress_bar=True)\n","\n","            print(f\"Generated embeddings shape: {self.embeddings.shape}\")\n","\n","        except Exception as e:\n","            print(f\"Error loading documents: {str(e)}\")\n","            print(traceback.format_exc())\n","            raise\n","\n","    def save_knowledge_base(self, file_path: str):\n","        \"\"\"Save the processed documents and embeddings.\"\"\"\n","        try:\n","            data = {\n","                \"documents\": self.documents,\n","                \"embeddings\": self.embeddings.tolist() if self.embeddings is not None else None\n","            }\n","\n","            with open(file_path, 'w', encoding='utf-8') as f:\n","                json.dump(data, f)\n","            print(f\"Knowledge base saved to {file_path}\")\n","\n","        except Exception as e:\n","            print(f\"Error saving knowledge base: {str(e)}\")\n","            print(traceback.format_exc())\n","\n","    def load_knowledge_base(self, file_path: str):\n","        \"\"\"Load previously processed documents and embeddings.\"\"\"\n","        try:\n","            print(f\"Loading knowledge base from {file_path}\")\n","            with open(file_path, 'r', encoding='utf-8') as f:\n","                data = json.load(f)\n","\n","            if \"documents\" in data and \"embeddings\" in data:\n","                self.documents = data[\"documents\"]\n","                self.embeddings = np.array(data[\"embeddings\"]) if data[\"embeddings\"] else None\n","                print(f\"Loaded {len(self.documents)} documents and embeddings shape: {self.embeddings.shape if self.embeddings is not None else None}\")\n","            else:\n","                raise ValueError(\"JSON file does not contain required keys 'documents' and 'embeddings'\")\n","\n","        except Exception as e:\n","            print(f\"Error loading knowledge base: {str(e)}\")\n","            print(traceback.format_exc())\n","            raise\n","\n","    def get_response(self, query: str, top_k: int = 3) -> Dict:\n","        \"\"\"Process query and return response with relevant context.\"\"\"\n","        try:\n","            start_time = time.time()\n","\n","            print(f\"Processing query: {query}\")\n","\n","            if not query:\n","                return {\n","                    \"query\": query,\n","                    \"response\": \"Empty query received\",\n","                    \"relevant_documents\": [],\n","                    \"processing_time\": 0\n","                }\n","\n","            # Check if embeddings exist\n","            if self.embeddings is None:\n","                print(\"No embeddings found\")\n","                return {\n","                    \"query\": query,\n","                    \"response\": \"System not initialized properly. No embeddings found.\",\n","                    \"relevant_documents\": [],\n","                    \"processing_time\": time.time() - start_time\n","                }\n","\n","            # Generate query embedding\n","            print(\"Generating query embedding...\")\n","            query_embedding = self.encoder.encode(query)\n","            print(\"Query embedding generated successfully\")\n","\n","            # Calculate similarities\n","            print(\"Calculating similarities...\")\n","            similarities = cosine_similarity([query_embedding], self.embeddings)[0]\n","            print(f\"Max similarity score: {similarities.max()}\")\n","\n","            if similarities.max() < 0.2:\n","                return {\n","                    \"query\": query,\n","                    \"response\": \"No relevant information found\",\n","                    \"relevant_documents\": [],\n","                    \"processing_time\": time.time() - start_time\n","                }\n","\n","            # Get top-k most similar documents\n","            top_indices = np.argsort(similarities)[-top_k:][::-1]\n","\n","            relevant_docs = []\n","            for idx in top_indices:\n","                doc = self.documents[idx]\n","                relevant_docs.append({\n","                    \"content\": doc[\"content\"],\n","                    \"metadata\": doc[\"metadata\"],\n","                    \"similarity\": float(similarities[idx])\n","                })\n","\n","            response = self._generate_simple_response(query, relevant_docs)\n","\n","            processing_time = time.time() - start_time\n","\n","            return {\n","                \"query\": query,\n","                \"response\": response,\n","                \"relevant_documents\": relevant_docs,\n","                \"processing_time\": processing_time\n","            }\n","\n","        except Exception as e:\n","            print(f\"Error in get_response: {str(e)}\")\n","            print(traceback.format_exc())\n","            return {\n","                \"query\": query,\n","                \"response\": f\"Error processing query: {str(e)}\",\n","                \"relevant_documents\": [],\n","                \"processing_time\": 0\n","            }\n","\n","    def _generate_simple_response(self, query: str, relevant_docs: List[Dict]) -> str:\n","        \"\"\"Generate a simple response based on the most relevant document.\"\"\"\n","        if not relevant_docs:\n","            return \"No relevant information found\"\n","\n","        return relevant_docs[0][\"content\"]"],"metadata":{"id":"MCNWHaRb8jYy","executionInfo":{"status":"ok","timestamp":1737113103550,"user_tz":-330,"elapsed":560,"user":{"displayName":"SIDDHANT BISHT","userId":"12873535686418561845"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["try:\n","    # Initialize chatbot\n","    print(\"Initializing chatbot...\")\n","    chatbot = CSEChatbot()\n","    print(\"Chatbot initialized successfully\")\n","\n","    # Check for existing knowledge base\n","    kb_path = \"knowledge_base.json\"\n","    if os.path.exists(kb_path):\n","        print(\"Loading existing knowledge base...\")\n","        chatbot.load_knowledge_base(kb_path)\n","        print(\"Knowledge base loaded successfully\")\n","        print(f\"Number of documents loaded: {len(chatbot.documents)}\")\n","        print(f\"Embeddings shape: {chatbot.embeddings.shape if chatbot.embeddings is not None else None}\")\n","    else:\n","        print(\"Processing documents...\")\n","        chatbot.load_documents(upload_directory)\n","        print(f\"Documents processed. Number of documents: {len(chatbot.documents)}\")\n","        chatbot.save_knowledge_base(kb_path)\n","        print(\"Knowledge base saved successfully\")\n","except Exception as e:\n","    print(f\"Error during initialization: {str(e)}\")\n","    print(traceback.format_exc())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4trZ6lem9Oq3","executionInfo":{"status":"ok","timestamp":1737113142983,"user_tz":-330,"elapsed":1774,"user":{"displayName":"SIDDHANT BISHT","userId":"12873535686418561845"}},"outputId":"c59b1a12-4f32-4be3-db88-d9b61e08089e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing chatbot...\n","Initializing SentenceTransformer...\n","Initialization successful\n","Chatbot initialized successfully\n","Loading existing knowledge base...\n","Loading knowledge base from knowledge_base.json\n","Loaded 13 documents and embeddings shape: (13, 384)\n","Knowledge base loaded successfully\n","Number of documents loaded: 13\n","Embeddings shape: (13, 384)\n"]}]},{"cell_type":"code","source":["# Install required packages\n","!pip install flask flask-cors\n","\n","from flask import Flask, request, jsonify, render_template_string\n","from flask_cors import CORS\n","import threading\n","from google.colab import output\n","import IPython\n","import traceback  # Add this import\n","\n","app = Flask(__name__)\n","CORS(app)\n","\n","# HTML template for the frontend\n","HTML_TEMPLATE = \"\"\"\n","<!DOCTYPE html>\n","<html>\n","<head>\n","    <title>CSE Department Chatbot</title>\n","    <style>\n","        body {\n","            font-family: Arial, sans-serif;\n","            max-width: 800px;\n","            margin: 0 auto;\n","            padding: 20px;\n","            background-color: #f5f5f5;\n","        }\n","        .chat-container {\n","            background-color: white;\n","            border-radius: 10px;\n","            padding: 20px;\n","            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n","        }\n","        .input-container {\n","            display: flex;\n","            gap: 10px;\n","            margin-top: 20px;\n","        }\n","        #questionInput {\n","            flex-grow: 1;\n","            padding: 10px;\n","            border: 1px solid #ddd;\n","            border-radius: 5px;\n","        }\n","        button {\n","            padding: 10px 20px;\n","            background-color: #007bff;\n","            color: white;\n","            border: none;\n","            border-radius: 5px;\n","            cursor: pointer;\n","        }\n","        button:hover {\n","            background-color: #0056b3;\n","        }\n","        #response {\n","            margin-top: 20px;\n","            white-space: pre-wrap;\n","        }\n","        .source-document {\n","            margin-top: 10px;\n","            padding: 10px;\n","            background-color: #f8f9fa;\n","            border-radius: 5px;\n","        }\n","        .loading {\n","            display: none;\n","            margin-top: 20px;\n","            color: #666;\n","        }\n","    </style>\n","</head>\n","<body>\n","    <div class=\"chat-container\">\n","        <h1>CSE Department Chatbot</h1>\n","        <div class=\"input-container\">\n","            <input type=\"text\" id=\"questionInput\" placeholder=\"Ask your question...\">\n","            <button onclick=\"askQuestion()\">Ask</button>\n","        </div>\n","        <div id=\"loading\" class=\"loading\">Processing your question...</div>\n","        <div id=\"response\"></div>\n","    </div>\n","\n","    <script>\n","        async function askQuestion() {\n","            const questionInput = document.getElementById('questionInput');\n","            const responseDiv = document.getElementById('response');\n","            const loadingDiv = document.getElementById('loading');\n","            const question = questionInput.value.trim();\n","\n","            if (!question) return;\n","\n","            // Show loading message\n","            loadingDiv.style.display = 'block';\n","            responseDiv.innerHTML = '';\n","\n","            try {\n","                const response = await fetch('/ask', {\n","                    method: 'POST',\n","                    headers: {\n","                        'Content-Type': 'application/json',\n","                    },\n","                    body: JSON.stringify({ question: question })\n","                });\n","\n","                const data = await response.json();\n","\n","                // Hide loading message\n","                loadingDiv.style.display = 'none';\n","\n","                // Display response\n","                let responseHtml = `<h3>Response:</h3><p>${data.response}</p>`;\n","\n","                if (data.relevant_documents && data.relevant_documents.length > 0) {\n","                    responseHtml += '<h3>Source Documents:</h3>';\n","                    data.relevant_documents.forEach((doc, index) => {\n","                        responseHtml += `\n","                            <div class=\"source-document\">\n","                                <p><strong>Source ${index + 1}</strong> (Similarity: ${doc.similarity.toFixed(2)})</p>\n","                                <p>File: ${doc.metadata.source}</p>\n","                            </div>\n","                        `;\n","                    });\n","                }\n","\n","                responseHtml += `<p><em>Processing time: ${data.processing_time.toFixed(2)} seconds</em></p>`;\n","                responseDiv.innerHTML = responseHtml;\n","\n","            } catch (error) {\n","                loadingDiv.style.display = 'none';\n","                responseDiv.innerHTML = '<p style=\"color: red;\">Error processing your question. Please try again.</p>';\n","                console.error('Error:', error);\n","            }\n","        }\n","\n","        // Allow Enter key to submit question\n","        document.getElementById('questionInput').addEventListener('keypress', function(e) {\n","            if (e.key === 'Enter') {\n","                askQuestion();\n","            }\n","        });\n","    </script>\n","</body>\n","</html>\n","\"\"\"\n","\n","@app.route('/')\n","def home():\n","    return render_template_string(HTML_TEMPLATE)\n","\n","@app.route('/ask', methods=['POST'])\n","def ask():\n","    try:\n","        data = request.json\n","        question = data.get('question', '')\n","\n","        if not question:\n","            return jsonify({'error': 'Question is empty'}), 400\n","\n","        # Add debug print\n","        print(f\"Received question: {question}\")\n","\n","        result = chatbot.get_response(question)\n","\n","        # Add debug print\n","        print(f\"Generated response: {result}\")\n","\n","        return jsonify(result)\n","\n","    except Exception as e:\n","        # Print the full error traceback\n","        print(\"Error occurred:\")\n","        print(traceback.format_exc())\n","        return jsonify({\n","            'error': str(e),\n","            'traceback': traceback.format_exc()\n","        }), 500\n","\n","def run_flask():\n","    app.run(port=8000, debug=True)  # Add debug=True\n","\n","# Start Flask server\n","flask_thread = threading.Thread(target=run_flask)\n","flask_thread.daemon = True\n","flask_thread.start()\n","\n","# Display the URL where the app can be accessed\n","output.serve_kernel_port_as_window(8000)\n","print(\"Chatbot web interface is running! Click the URL above to open it in a new window.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"pDc9sVtL9SGf","executionInfo":{"status":"ok","timestamp":1737113669419,"user_tz":-330,"elapsed":3002,"user":{"displayName":"SIDDHANT BISHT","userId":"12873535686418561845"}},"outputId":"df1dbf0c-56d8-43c3-e85f-395eb2871bef"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n","Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (5.0.0)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, text, element) => {\n","    if (!google.colab.kernel.accessAllowed) {\n","      return;\n","    }\n","    element.appendChild(document.createTextNode(''));\n","    const url = await google.colab.kernel.proxyPort(port);\n","    const anchor = document.createElement('a');\n","    anchor.href = new URL(path, url).toString();\n","    anchor.target = '_blank';\n","    anchor.setAttribute('data-href', url + path);\n","    anchor.textContent = text;\n","    element.appendChild(anchor);\n","  })(8000, \"/\", \"https://localhost:8000/\", window.element)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[31mWarning: This function may stop working due to changes in browser security.\n","Try `serve_kernel_port_as_iframe` instead. \u001b[0m\n","Chatbot web interface is running! Click the URL above to open it in a new window.\n"," * Serving Flask app '__main__'\n"," * Debug mode: on\n"]},{"output_type":"stream","name":"stderr","text":["Address already in use\n","Port 8000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"]}]}]}